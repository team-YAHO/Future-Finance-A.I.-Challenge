{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0869bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76769e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>F0(pitch)</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934.456137</td>\n",
       "      <td>1867.766912</td>\n",
       "      <td>2958.658056</td>\n",
       "      <td>4026.961381</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1338.936874</td>\n",
       "      <td>2694.203872</td>\n",
       "      <td>2875.547156</td>\n",
       "      <td>4229.574451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160.135803</td>\n",
       "      <td>2144.572867</td>\n",
       "      <td>3476.990084</td>\n",
       "      <td>4433.055683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.203260</td>\n",
       "      <td>1472.209366</td>\n",
       "      <td>2708.645128</td>\n",
       "      <td>3839.022388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381.149933</td>\n",
       "      <td>1721.053643</td>\n",
       "      <td>2682.587186</td>\n",
       "      <td>3957.900682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  F0(pitch)           F1           F2           F3           F4  F5\n",
       "0   BYJ        NaN   934.456137  1867.766912  2958.658056  4026.961381 NaN\n",
       "1   BYJ        NaN  1338.936874  2694.203872  2875.547156  4229.574451 NaN\n",
       "2   BYJ        NaN  1160.135803  2144.572867  3476.990084  4433.055683 NaN\n",
       "3   BYJ        NaN   211.203260  1472.209366  2708.645128  3839.022388 NaN\n",
       "4   BYJ        NaN   381.149933  1721.053643  2682.587186  3957.900682 NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e36a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:\n",
      "['BYJ' 'HYN' 'SJW']\n"
     ]
    }
   ],
   "source": [
    "print(\"라벨:\", data[\"Label\"].unique(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341450b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3명이 7개의 피쳐에 대해 어떤 분포를 가지고 있는지 시각화\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g = sns.pairplot(data, hue=\"Label\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44ece5",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419c970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.fillna(value=0)\n",
    "user_id_arr = train_data['Label'].unique()\n",
    "user_count = user_id_arr.shape[0]\n",
    "train_data = pd.get_dummies(train_data)\n",
    "train_data = train_data.astype('float64')\n",
    "train_data = shuffle(train_data)\n",
    "X_len=len(train_data.columns)-user_count\n",
    "y_len=user_count\n",
    "X=train_data.iloc[:,0:X_len]\n",
    "y=train_data.iloc[:,-user_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c3ada92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0(pitch)</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1956.155406</td>\n",
       "      <td>2710.009480</td>\n",
       "      <td>3816.408405</td>\n",
       "      <td>4409.109038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>914.393773</td>\n",
       "      <td>2213.054230</td>\n",
       "      <td>3297.138564</td>\n",
       "      <td>4341.879894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>918.327711</td>\n",
       "      <td>2040.409655</td>\n",
       "      <td>3128.793551</td>\n",
       "      <td>4304.133192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>635.351407</td>\n",
       "      <td>1792.649081</td>\n",
       "      <td>2465.669464</td>\n",
       "      <td>4044.486379</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>196.552652</td>\n",
       "      <td>387.393985</td>\n",
       "      <td>2163.231315</td>\n",
       "      <td>2968.388701</td>\n",
       "      <td>3673.923567</td>\n",
       "      <td>4831.864733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F0(pitch)           F1           F2           F3           F4  \\\n",
       "576    0.000000  1956.155406  2710.009480  3816.408405  4409.109038   \n",
       "445    0.000000   914.393773  2213.054230  3297.138564  4341.879894   \n",
       "484    0.000000   918.327711  2040.409655  3128.793551  4304.133192   \n",
       "150    0.000000   635.351407  1792.649081  2465.669464  4044.486379   \n",
       "508  196.552652   387.393985  2163.231315  2968.388701  3673.923567   \n",
       "\n",
       "              F5  \n",
       "576     0.000000  \n",
       "445     0.000000  \n",
       "484     0.000000  \n",
       "150     0.000000  \n",
       "508  4831.864733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69dc48d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_BYJ</th>\n",
       "      <th>Label_HYN</th>\n",
       "      <th>Label_SJW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label_BYJ  Label_HYN  Label_SJW\n",
       "576        0.0        0.0        1.0\n",
       "445        0.0        0.0        1.0\n",
       "484        0.0        0.0        1.0\n",
       "150        1.0        0.0        0.0\n",
       "508        0.0        0.0        1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece3ee1",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9a5416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                105       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ready model\n",
    "\n",
    "k=20 #fold\n",
    "num_val_samples=len(X)//20\n",
    "\n",
    "sc = StandardScaler()\n",
    "classifier = Sequential()\n",
    "\n",
    "unit = 15\n",
    "rate = 0.3\n",
    "\n",
    "# 1st layer(input)\n",
    "classifier.add(Dense(units = unit, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = X_len))\n",
    "\n",
    "# 2nd layer\n",
    "classifier.add(Dense(units = unit, kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate))\n",
    "\n",
    "# 3rd layer\n",
    "classifier.add(Dense(units = unit, kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate))\n",
    "\n",
    "# 4th layer\n",
    "classifier.add(Dense(units = unit, kernel_initializer = 'glorot_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate))\n",
    "\n",
    "# 5th layer(output)\n",
    "classifier.add(Dense(units = user_count, kernel_initializer = 'glorot_uniform', activation = 'softmax'))\n",
    "\n",
    "# compile\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccd3a70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold num # 1\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 999us/step - loss: 1.1029 - accuracy: 0.3494\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0913 - accuracy: 0.3782\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0777 - accuracy: 0.3574\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 961us/step - loss: 1.0665 - accuracy: 0.3734\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.4006\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0700 - accuracy: 0.4407\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0613 - accuracy: 0.4391\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0644 - accuracy: 0.4151\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 1.0633 - accuracy: 0.4279\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 936us/step - loss: 1.0572 - accuracy: 0.4375\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0549 - accuracy: 0.4439\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0540 - accuracy: 0.4343\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0403 - accuracy: 0.4760\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 996us/step - loss: 1.0429 - accuracy: 0.4679\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 951us/step - loss: 1.0325 - accuracy: 0.4776\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0215 - accuracy: 0.4679\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0410 - accuracy: 0.4856\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.4679\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0299 - accuracy: 0.4551\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0231 - accuracy: 0.4631\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0121 - accuracy: 0.4808\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0055 - accuracy: 0.4744\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0195 - accuracy: 0.4936\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0012 - accuracy: 0.5032\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 939us/step - loss: 0.9854 - accuracy: 0.5433\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9881 - accuracy: 0.5240\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9991 - accuracy: 0.5401\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0086 - accuracy: 0.5048\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.9973 - accuracy: 0.5032\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0017 - accuracy: 0.4984\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.9843 - accuracy: 0.4888\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.9586 - accuracy: 0.5641\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 944us/step - loss: 0.9707 - accuracy: 0.5304\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.9688 - accuracy: 0.5353\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.9728 - accuracy: 0.5353\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.9637 - accuracy: 0.5401\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 974us/step - loss: 0.9624 - accuracy: 0.5465\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 997us/step - loss: 0.9637 - accuracy: 0.5433\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9564 - accuracy: 0.5545\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9589 - accuracy: 0.5593\n",
      "fold num # 2\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9459 - accuracy: 0.5641\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 827us/step - loss: 0.9492 - accuracy: 0.5641\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 862us/step - loss: 0.9560 - accuracy: 0.5513\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.9147 - accuracy: 0.5705\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 924us/step - loss: 0.9554 - accuracy: 0.5417\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 932us/step - loss: 0.9685 - accuracy: 0.5433\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 971us/step - loss: 0.9416 - accuracy: 0.5657\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9648 - accuracy: 0.5337\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9486 - accuracy: 0.5449\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9270 - accuracy: 0.5625\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.9126 - accuracy: 0.5849\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 899us/step - loss: 0.9325 - accuracy: 0.5769\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 970us/step - loss: 0.9562 - accuracy: 0.5641\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9246 - accuracy: 0.5705\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 991us/step - loss: 0.9345 - accuracy: 0.5497\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9098 - accuracy: 0.5577\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9024 - accuracy: 0.5929\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5705\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.9326 - accuracy: 0.5721\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9155 - accuracy: 0.5817\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.9314 - accuracy: 0.5994\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 849us/step - loss: 0.8862 - accuracy: 0.5897\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 815us/step - loss: 0.8840 - accuracy: 0.5849\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.8902 - accuracy: 0.6010\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 715us/step - loss: 0.9171 - accuracy: 0.5545\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.8627 - accuracy: 0.6250\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8996 - accuracy: 0.5962\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.8999 - accuracy: 0.5897\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8859 - accuracy: 0.5946\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.8822 - accuracy: 0.6106\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.62 - 0s 1ms/step - loss: 0.8897 - accuracy: 0.5946\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 951us/step - loss: 0.8661 - accuracy: 0.6234\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.8856 - accuracy: 0.6058\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.8746 - accuracy: 0.5978\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8669 - accuracy: 0.6186\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.8667 - accuracy: 0.6138\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.8876 - accuracy: 0.6122\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.8597 - accuracy: 0.6202\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.8405 - accuracy: 0.6298\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8915 - accuracy: 0.5962\n",
      "fold num # 3\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8631 - accuracy: 0.6490\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8936 - accuracy: 0.6394\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8809 - accuracy: 0.5929\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8470 - accuracy: 0.6314\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8327 - accuracy: 0.6667\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8551 - accuracy: 0.6506\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.8692 - accuracy: 0.6058\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8504 - accuracy: 0.6314\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8427 - accuracy: 0.6122\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 952us/step - loss: 0.8544 - accuracy: 0.6218\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8503 - accuracy: 0.6266\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.8603 - accuracy: 0.6314\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 730us/step - loss: 0.8460 - accuracy: 0.6410\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 902us/step - loss: 0.8255 - accuracy: 0.6506\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.8253 - accuracy: 0.6410\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.8444 - accuracy: 0.6298\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.8144 - accuracy: 0.6571\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.8008 - accuracy: 0.6458\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.8135 - accuracy: 0.6571\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 600us/step - loss: 0.8104 - accuracy: 0.6554\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 629us/step - loss: 0.8280 - accuracy: 0.6330\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.8196 - accuracy: 0.6506\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.8244 - accuracy: 0.6571\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 670us/step - loss: 0.8074 - accuracy: 0.6490\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 720us/step - loss: 0.8565 - accuracy: 0.6298\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 693us/step - loss: 0.8213 - accuracy: 0.6811\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 695us/step - loss: 0.8192 - accuracy: 0.6506\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.8253 - accuracy: 0.6506\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.8298 - accuracy: 0.6538\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.8341 - accuracy: 0.6603\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.8159 - accuracy: 0.6651\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.8055 - accuracy: 0.6442\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 694us/step - loss: 0.8176 - accuracy: 0.6571\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.8026 - accuracy: 0.6779\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7858 - accuracy: 0.6651\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 742us/step - loss: 0.8044 - accuracy: 0.6715\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 692us/step - loss: 0.7724 - accuracy: 0.6811\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 666us/step - loss: 0.8149 - accuracy: 0.6442\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 725us/step - loss: 0.7729 - accuracy: 0.6699\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 720us/step - loss: 0.7910 - accuracy: 0.6554\n",
      "fold num # 4\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 931us/step - loss: 0.7940 - accuracy: 0.6811\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 893us/step - loss: 0.7728 - accuracy: 0.6554\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.7958 - accuracy: 0.6667\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.7858 - accuracy: 0.6571\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 836us/step - loss: 0.7914 - accuracy: 0.6442\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 668us/step - loss: 0.7846 - accuracy: 0.6763\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7920 - accuracy: 0.6827\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.7544 - accuracy: 0.6859\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 705us/step - loss: 0.7838 - accuracy: 0.6811\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.7736 - accuracy: 0.6731\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7760 - accuracy: 0.6683\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 640us/step - loss: 0.7903 - accuracy: 0.6603\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7804 - accuracy: 0.6955\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7951 - accuracy: 0.6474\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 838us/step - loss: 0.7643 - accuracy: 0.6843\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.7521 - accuracy: 0.6875\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.7904 - accuracy: 0.6763\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.7706 - accuracy: 0.6554\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.7882 - accuracy: 0.6715\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.7618 - accuracy: 0.6795\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.7884 - accuracy: 0.6763\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7701 - accuracy: 0.6587\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7903 - accuracy: 0.6603\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7818 - accuracy: 0.6731\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.7313 - accuracy: 0.7147\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7540 - accuracy: 0.6747\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.6939\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 974us/step - loss: 0.7656 - accuracy: 0.6603\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.7019\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7536 - accuracy: 0.6619\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7655 - accuracy: 0.6699\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7699 - accuracy: 0.6795\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7661 - accuracy: 0.6763\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.7748 - accuracy: 0.6891\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.7681 - accuracy: 0.6715\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.7019\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.7722 - accuracy: 0.6683\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7684 - accuracy: 0.6827\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 985us/step - loss: 0.7876 - accuracy: 0.6747\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 992us/step - loss: 0.7227 - accuracy: 0.6939\n",
      "fold num # 5\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8016 - accuracy: 0.6635\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 998us/step - loss: 0.8064 - accuracy: 0.6667\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6971\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6923\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6699\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.6939\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.6795\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.7019\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.7003\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.7212\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.7003\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7590 - accuracy: 0.6811\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.6795\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.6635\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.6971\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.7051\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.7003\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.7067\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.7067\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.7083\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.6843\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.7196\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.6875\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.7003\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.6971\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.70 - 0s 1ms/step - loss: 0.7275 - accuracy: 0.7083\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.6875\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.7115\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.7003\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7071 - accuracy: 0.7308\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6731 - accuracy: 0.7196\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.7401 - accuracy: 0.6939\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 768us/step - loss: 0.7183 - accuracy: 0.7051\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 706us/step - loss: 0.7160 - accuracy: 0.7179\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 698us/step - loss: 0.7353 - accuracy: 0.7051\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 765us/step - loss: 0.7027 - accuracy: 0.7035\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 767us/step - loss: 0.7284 - accuracy: 0.7019\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.7073 - accuracy: 0.6971\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7355 - accuracy: 0.6795\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7258 - accuracy: 0.6939\n",
      "fold num # 6\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7568 - accuracy: 0.6843\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 925us/step - loss: 0.7439 - accuracy: 0.7019\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.6923\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 991us/step - loss: 0.7070 - accuracy: 0.7179\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 839us/step - loss: 0.7360 - accuracy: 0.7019\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 942us/step - loss: 0.7199 - accuracy: 0.7115\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6979 - accuracy: 0.7179\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.7173 - accuracy: 0.7067\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7254 - accuracy: 0.7019\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.7083\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.7147\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.7276\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.7051\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7244\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6987\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.7260\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 971us/step - loss: 0.7138 - accuracy: 0.7083\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 981us/step - loss: 0.7142 - accuracy: 0.7051\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6960 - accuracy: 0.7212\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.7067\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 990us/step - loss: 0.6998 - accuracy: 0.6987\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 955us/step - loss: 0.7194 - accuracy: 0.7035\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 936us/step - loss: 0.6801 - accuracy: 0.7292\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 851us/step - loss: 0.7133 - accuracy: 0.7115\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.7048 - accuracy: 0.7099\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 788us/step - loss: 0.7334 - accuracy: 0.7035\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 832us/step - loss: 0.6990 - accuracy: 0.7131\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.7241 - accuracy: 0.6987\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.7126 - accuracy: 0.7115\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6615 - accuracy: 0.7179\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 701us/step - loss: 0.7145 - accuracy: 0.7051\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.6908 - accuracy: 0.7324\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 712us/step - loss: 0.6676 - accuracy: 0.7356\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7163 - accuracy: 0.7179\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 666us/step - loss: 0.6993 - accuracy: 0.7051\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7113 - accuracy: 0.6987\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7223 - accuracy: 0.7179\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7062 - accuracy: 0.7163\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.6882 - accuracy: 0.7147\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 763us/step - loss: 0.7090 - accuracy: 0.7051\n",
      "fold num # 7\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.7035\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.7308\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7147\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.7196\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 966us/step - loss: 0.6949 - accuracy: 0.7228\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.7147\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6971\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.7244\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6915 - accuracy: 0.7131\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6728 - accuracy: 0.7388\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7192 - accuracy: 0.7003\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7261 - accuracy: 0.7035\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7020 - accuracy: 0.7163\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 628us/step - loss: 0.6896 - accuracy: 0.7228\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 668us/step - loss: 0.7129 - accuracy: 0.7003\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.7064 - accuracy: 0.7067\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7140 - accuracy: 0.6875\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7123 - accuracy: 0.7308\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.7019 - accuracy: 0.7147\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6742 - accuracy: 0.7083\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 859us/step - loss: 0.7030 - accuracy: 0.7131\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.85 - 0s 818us/step - loss: 0.7036 - accuracy: 0.7003\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.82 - 0s 678us/step - loss: 0.7148 - accuracy: 0.7276\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6681 - accuracy: 0.7292\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 736us/step - loss: 0.6915 - accuracy: 0.7099\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.7090 - accuracy: 0.7228\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6927 - accuracy: 0.7196\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 732us/step - loss: 0.6923 - accuracy: 0.7292\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6976 - accuracy: 0.7212\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.7000 - accuracy: 0.7131\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.6587 - accuracy: 0.7212\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 719us/step - loss: 0.7012 - accuracy: 0.7228\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 774us/step - loss: 0.6927 - accuracy: 0.7179\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6886 - accuracy: 0.7308\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.6592 - accuracy: 0.7468\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.6719 - accuracy: 0.7324\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6668 - accuracy: 0.7308\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 701us/step - loss: 0.6933 - accuracy: 0.7196\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.6712 - accuracy: 0.7340\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6784 - accuracy: 0.7388\n",
      "fold num # 8\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.7143 - accuracy: 0.7003\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 966us/step - loss: 0.6759 - accuracy: 0.7115\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.7340\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.7003\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6987\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 932us/step - loss: 0.7162 - accuracy: 0.7051\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 730us/step - loss: 0.6759 - accuracy: 0.7147\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 804us/step - loss: 0.6980 - accuracy: 0.7067\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6801 - accuracy: 0.7099\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6856 - accuracy: 0.7244\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.7136 - accuracy: 0.6779\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 705us/step - loss: 0.6675 - accuracy: 0.7292\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.6798 - accuracy: 0.7067\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6702 - accuracy: 0.7212\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 651us/step - loss: 0.6561 - accuracy: 0.7196\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 739us/step - loss: 0.6986 - accuracy: 0.7147\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6821 - accuracy: 0.7179\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 737us/step - loss: 0.7067 - accuracy: 0.7228\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 692us/step - loss: 0.6909 - accuracy: 0.7163\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6637 - accuracy: 0.7420\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6736 - accuracy: 0.7051\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6838 - accuracy: 0.7436\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6724 - accuracy: 0.7147\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.7186 - accuracy: 0.7051\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6531 - accuracy: 0.7420\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7044 - accuracy: 0.7131\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6565 - accuracy: 0.7372\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.6991 - accuracy: 0.7099\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6578 - accuracy: 0.7372\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.6990 - accuracy: 0.7099\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7051 - accuracy: 0.7196\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6894 - accuracy: 0.7147\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.6743 - accuracy: 0.7276\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6630 - accuracy: 0.7324\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6721 - accuracy: 0.7308\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6763 - accuracy: 0.7292\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6718 - accuracy: 0.7051\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 774us/step - loss: 0.6759 - accuracy: 0.7179\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 762us/step - loss: 0.6808 - accuracy: 0.7163\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 679us/step - loss: 0.6762 - accuracy: 0.7228\n",
      "fold num # 9\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7099\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.7244\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.7244\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 898us/step - loss: 0.6734 - accuracy: 0.7115\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.6590 - accuracy: 0.7324\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.7260\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 957us/step - loss: 0.6824 - accuracy: 0.7147\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.7147\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 984us/step - loss: 0.6749 - accuracy: 0.7067\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.7308\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6864 - accuracy: 0.7452\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 884us/step - loss: 0.6510 - accuracy: 0.7340\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 983us/step - loss: 0.6991 - accuracy: 0.7196\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6896 - accuracy: 0.7196\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6685 - accuracy: 0.7292\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 600us/step - loss: 0.6537 - accuracy: 0.7452\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6426 - accuracy: 0.7212\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6637 - accuracy: 0.7436\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6595 - accuracy: 0.7340\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6657 - accuracy: 0.7244\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 707us/step - loss: 0.6684 - accuracy: 0.7003\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 745us/step - loss: 0.6579 - accuracy: 0.7308\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6516 - accuracy: 0.7276\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 690us/step - loss: 0.6949 - accuracy: 0.7372\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6609 - accuracy: 0.7244\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6631 - accuracy: 0.7324\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6420 - accuracy: 0.7163\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6554 - accuracy: 0.7372\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 694us/step - loss: 0.6587 - accuracy: 0.7580\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6869 - accuracy: 0.7260\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6622 - accuracy: 0.7179\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 751us/step - loss: 0.6455 - accuracy: 0.7532\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6645 - accuracy: 0.7163\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6199 - accuracy: 0.7516\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6517 - accuracy: 0.7388\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6689 - accuracy: 0.7244\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6447 - accuracy: 0.7436\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6592 - accuracy: 0.7324\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6642 - accuracy: 0.7436\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 728us/step - loss: 0.6868 - accuracy: 0.7163\n",
      "fold num # 10\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.7179\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7308\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.7067\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7308\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.7292\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.7115\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7388\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 972us/step - loss: 0.6903 - accuracy: 0.7228\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6405 - accuracy: 0.7500\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 860us/step - loss: 0.6636 - accuracy: 0.7276\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 898us/step - loss: 0.6654 - accuracy: 0.7356\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 844us/step - loss: 0.6624 - accuracy: 0.7228\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 910us/step - loss: 0.6852 - accuracy: 0.7067\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6699 - accuracy: 0.7212\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 746us/step - loss: 0.6714 - accuracy: 0.7308\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6515 - accuracy: 0.7420\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6392 - accuracy: 0.7468\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 738us/step - loss: 0.6600 - accuracy: 0.7324\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6781 - accuracy: 0.7228\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.7110 - accuracy: 0.7324\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6828 - accuracy: 0.7035\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6709 - accuracy: 0.7340\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.7404\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.7228\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.7612\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.7115\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.7468\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7420\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.7404\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.7404\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.7163\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.7244\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.7131\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.7179\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.7420\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.7308\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.7404\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.7516\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.7228\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.7356\n",
      "fold num # 11\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7228\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.7292\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.7260\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.7452\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.7356\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.7292\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.7244\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.7067\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.7548\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.7372\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.7692\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.7292\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.7228\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.7244\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.7372\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.7067\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.7276\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.7388\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.7372\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.7276\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.7115\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 967us/step - loss: 0.6569 - accuracy: 0.7452\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.7404\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.7356\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.7147\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.7388\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.6833 - accuracy: 0.7196\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.7404\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.7372\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.7452\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.7212\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.6396 - accuracy: 0.7484\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.7548\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.7388\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.6584 - accuracy: 0.7163\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.7356\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1000us/step - loss: 0.6595 - accuracy: 0.7292\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.7404\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.7276\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.7308\n",
      "fold num # 12\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.7468\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.7228\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.7404\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.7260\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.7436\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.7564\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.7260\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.7484\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.7452\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7372\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.7372\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.7468\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.7292\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.7260\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6207 - accuracy: 0.7356\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.7196\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.7308\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.7308\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.7244\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.7468\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7212\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.7372\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.7308\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.7212\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.7404\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.7212\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.7228\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.7404\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.7340\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.7372\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.7228\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.7228\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.7404\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.7372\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.7356\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.7372\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.7564\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.7372\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.7436\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.7564\n",
      "fold num # 13\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.7324\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.7308\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.7388\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.7196\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.7115\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.7372\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.7436\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.7548\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.7612\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.7372\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.7324\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7548\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.7468\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.7276\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7340\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.72 - 0s 1ms/step - loss: 0.6609 - accuracy: 0.7340\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.7340\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.7452\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.7468\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.7051\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.7404\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7740\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.7548\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.7660\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.7420\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.7324\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.7324\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.7228\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.7308\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.7131\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.7628\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.7324\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.7452\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.7067\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.7564\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7372\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.7452\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.7452\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.7452\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.7388\n",
      "fold num # 14\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.7276\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.7340\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.7324\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.7356\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.7340\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.7468\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.7404\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.7692\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.7340\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.7596\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.7644\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.7324\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.7372\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.7532\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.7436\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.7468\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.7548\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.7163\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.7356\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.7564\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.7468\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.7484\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.7516\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.7420\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.7484\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.7212\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.7548\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7500\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6207 - accuracy: 0.7676\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.7676\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.7644\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.7516\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.7516\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.7147\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.75 - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7612\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.7436\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.7163\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.7580\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.7308\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.7340\n",
      "fold num # 15\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.7644\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7308\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.70 - 0s 1ms/step - loss: 0.6287 - accuracy: 0.7404\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.7324\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.7388\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.7596\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.7436\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.7484\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.7548\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.7628\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.7516\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7612\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.7548\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.7372\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.7468\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.7484\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7340\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.7388\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.7436\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 987us/step - loss: 0.6146 - accuracy: 0.7372\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.6025 - accuracy: 0.7484\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6137 - accuracy: 0.7452\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.6109 - accuracy: 0.7532\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.5966 - accuracy: 0.7708\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6391 - accuracy: 0.7388\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 738us/step - loss: 0.5857 - accuracy: 0.7660\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 703us/step - loss: 0.6173 - accuracy: 0.7420\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6124 - accuracy: 0.7468\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6151 - accuracy: 0.7612\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 766us/step - loss: 0.5977 - accuracy: 0.7612\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6048 - accuracy: 0.7580\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 747us/step - loss: 0.5874 - accuracy: 0.7708\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 684us/step - loss: 0.6001 - accuracy: 0.7612\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 687us/step - loss: 0.6110 - accuracy: 0.7564\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 720us/step - loss: 0.6095 - accuracy: 0.7500\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.5964 - accuracy: 0.7564\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.5951 - accuracy: 0.7596\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6057 - accuracy: 0.7468\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5715 - accuracy: 0.7740\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6211 - accuracy: 0.7404\n",
      "fold num # 16\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.7436\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 887us/step - loss: 0.6065 - accuracy: 0.7564\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 900us/step - loss: 0.6227 - accuracy: 0.7500\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.7404\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6195 - accuracy: 0.7516\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6111 - accuracy: 0.7340\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6371 - accuracy: 0.7340\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.5901 - accuracy: 0.7500\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6267 - accuracy: 0.7516\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 826us/step - loss: 0.6245 - accuracy: 0.7468\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.6294 - accuracy: 0.7564\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6412 - accuracy: 0.7404\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6158 - accuracy: 0.7420\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 666us/step - loss: 0.6004 - accuracy: 0.7580\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6250 - accuracy: 0.7500\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6137 - accuracy: 0.7580\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6082 - accuracy: 0.7516\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5795 - accuracy: 0.7676\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6269 - accuracy: 0.7516\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6297 - accuracy: 0.7260\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6501 - accuracy: 0.7260\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6289 - accuracy: 0.7564\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 764us/step - loss: 0.6074 - accuracy: 0.7596\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 752us/step - loss: 0.5893 - accuracy: 0.7644\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 771us/step - loss: 0.6368 - accuracy: 0.7484\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5814 - accuracy: 0.7708\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 684us/step - loss: 0.5955 - accuracy: 0.7580\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5805 - accuracy: 0.7500\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 691us/step - loss: 0.6219 - accuracy: 0.7516\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6229 - accuracy: 0.7500\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6383 - accuracy: 0.7548\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 962us/step - loss: 0.6187 - accuracy: 0.7628\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 926us/step - loss: 0.5808 - accuracy: 0.7628\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.6017 - accuracy: 0.7564\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5990 - accuracy: 0.7756\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.6105 - accuracy: 0.7564\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 869us/step - loss: 0.6332 - accuracy: 0.7356\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6022 - accuracy: 0.7596\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5963 - accuracy: 0.7468\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 911us/step - loss: 0.6240 - accuracy: 0.7596\n",
      "fold num # 17\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.7452\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.7452\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.7596\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.7660\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.7772\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 941us/step - loss: 0.6081 - accuracy: 0.7580\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.7324\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5964 - accuracy: 0.7660\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 733us/step - loss: 0.6315 - accuracy: 0.7404\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6160 - accuracy: 0.7404\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 751us/step - loss: 0.6249 - accuracy: 0.7420\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 805us/step - loss: 0.5880 - accuracy: 0.7548\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.5986 - accuracy: 0.7500\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 811us/step - loss: 0.6215 - accuracy: 0.7612\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 710us/step - loss: 0.5993 - accuracy: 0.7628\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6357 - accuracy: 0.7452\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 781us/step - loss: 0.6643 - accuracy: 0.7340\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6391 - accuracy: 0.7244\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6338 - accuracy: 0.7388\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5934 - accuracy: 0.7692\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6313 - accuracy: 0.7372\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.6278 - accuracy: 0.7404\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 746us/step - loss: 0.5898 - accuracy: 0.7660\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6148 - accuracy: 0.7404\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6404 - accuracy: 0.7340\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 670us/step - loss: 0.6393 - accuracy: 0.7372\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6223 - accuracy: 0.7276\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6171 - accuracy: 0.7244\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6117 - accuracy: 0.7548\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 752us/step - loss: 0.5841 - accuracy: 0.7644\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6239 - accuracy: 0.7356\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6082 - accuracy: 0.7564\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5980 - accuracy: 0.7516\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6088 - accuracy: 0.7484\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6277 - accuracy: 0.7260\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 710us/step - loss: 0.5893 - accuracy: 0.7580\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 751us/step - loss: 0.6092 - accuracy: 0.7612\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 779us/step - loss: 0.6246 - accuracy: 0.7516\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 723us/step - loss: 0.6584 - accuracy: 0.7179\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 786us/step - loss: 0.5930 - accuracy: 0.7692\n",
      "fold num # 18\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.7676\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7500\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.7372\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.7420\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 934us/step - loss: 0.6077 - accuracy: 0.7596\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.7612\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 913us/step - loss: 0.6124 - accuracy: 0.7436\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.7356\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.7484\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.7644\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.7324\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.7452\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.7484\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.7532\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 868us/step - loss: 0.5978 - accuracy: 0.7484\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 974us/step - loss: 0.6316 - accuracy: 0.7212\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 951us/step - loss: 0.6108 - accuracy: 0.7484\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 979us/step - loss: 0.6039 - accuracy: 0.7452\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7660\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.7692\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 845us/step - loss: 0.6240 - accuracy: 0.7340\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.6283 - accuracy: 0.7420\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6275 - accuracy: 0.7644\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 847us/step - loss: 0.5829 - accuracy: 0.7628\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.6087 - accuracy: 0.7548\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 770us/step - loss: 0.6057 - accuracy: 0.7484\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5655 - accuracy: 0.7660\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 775us/step - loss: 0.6101 - accuracy: 0.7548\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6420 - accuracy: 0.7388\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6138 - accuracy: 0.7388\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6010 - accuracy: 0.7580\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 758us/step - loss: 0.5933 - accuracy: 0.7564\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6023 - accuracy: 0.7580\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6264 - accuracy: 0.7436\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 983us/step - loss: 0.5988 - accuracy: 0.7580\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 795us/step - loss: 0.6096 - accuracy: 0.7452\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 982us/step - loss: 0.6025 - accuracy: 0.7484\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.6071 - accuracy: 0.7356\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 824us/step - loss: 0.6248 - accuracy: 0.7484\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6138 - accuracy: 0.7388\n",
      "fold num # 19\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 964us/step - loss: 0.6420 - accuracy: 0.7260\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 961us/step - loss: 0.6208 - accuracy: 0.7500\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 856us/step - loss: 0.5804 - accuracy: 0.7788\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 714us/step - loss: 0.5814 - accuracy: 0.7628\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.6048 - accuracy: 0.7468\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6069 - accuracy: 0.7324\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 813us/step - loss: 0.6030 - accuracy: 0.7548\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 890us/step - loss: 0.5876 - accuracy: 0.7532\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6207 - accuracy: 0.7308\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6259 - accuracy: 0.7404\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 757us/step - loss: 0.6275 - accuracy: 0.7372\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6325 - accuracy: 0.7436\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 753us/step - loss: 0.6292 - accuracy: 0.7324\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 719us/step - loss: 0.6162 - accuracy: 0.7612\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 783us/step - loss: 0.6256 - accuracy: 0.7564\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6149 - accuracy: 0.7564\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.77 - 0s 800us/step - loss: 0.6127 - accuracy: 0.7660\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 799us/step - loss: 0.6121 - accuracy: 0.7420\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5765 - accuracy: 0.7788\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.6125 - accuracy: 0.7436\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5641 - accuracy: 0.7612\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5931 - accuracy: 0.7628\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 772us/step - loss: 0.5976 - accuracy: 0.7532\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6319 - accuracy: 0.7388\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 686us/step - loss: 0.6155 - accuracy: 0.7548\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6504 - accuracy: 0.7436\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 825us/step - loss: 0.5991 - accuracy: 0.7628\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6151 - accuracy: 0.7404\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 768us/step - loss: 0.6135 - accuracy: 0.7548\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6370 - accuracy: 0.7372\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 741us/step - loss: 0.6112 - accuracy: 0.7548\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6583 - accuracy: 0.7292\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6151 - accuracy: 0.7692\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5900 - accuracy: 0.7612\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 819us/step - loss: 0.5953 - accuracy: 0.7628\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6414 - accuracy: 0.7612\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5898 - accuracy: 0.7516\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6067 - accuracy: 0.7596\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5865 - accuracy: 0.7564\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.6249 - accuracy: 0.7340\n",
      "fold num # 20\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.7532\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 0s 907us/step - loss: 0.6396 - accuracy: 0.7548\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 0s 933us/step - loss: 0.6228 - accuracy: 0.7436\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 0s 895us/step - loss: 0.6080 - accuracy: 0.7580\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 0s 734us/step - loss: 0.6036 - accuracy: 0.7468\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 0s 667us/step - loss: 0.5791 - accuracy: 0.7484\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 0s 749us/step - loss: 0.6015 - accuracy: 0.7452\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 0s 866us/step - loss: 0.6185 - accuracy: 0.7628\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 0s 760us/step - loss: 0.5895 - accuracy: 0.7500\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.5871 - accuracy: 0.7580\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 0s 807us/step - loss: 0.5989 - accuracy: 0.7580\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.6139 - accuracy: 0.7516\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.6024 - accuracy: 0.7516\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 0s 790us/step - loss: 0.5854 - accuracy: 0.7580\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 0s 769us/step - loss: 0.5861 - accuracy: 0.7580\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5922 - accuracy: 0.7532\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 0s 867us/step - loss: 0.6288 - accuracy: 0.7292\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5892 - accuracy: 0.7660\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6162 - accuracy: 0.7468\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 0s 796us/step - loss: 0.6119 - accuracy: 0.7372\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 0s 953us/step - loss: 0.6116 - accuracy: 0.7436\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7436\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 0s 881us/step - loss: 0.6171 - accuracy: 0.7436\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 0s 888us/step - loss: 0.6286 - accuracy: 0.7356\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 0s 733us/step - loss: 0.5666 - accuracy: 0.7596\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.6065 - accuracy: 0.7660\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5777 - accuracy: 0.7580\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 0s 778us/step - loss: 0.6266 - accuracy: 0.7548\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 0s 771us/step - loss: 0.6248 - accuracy: 0.7404\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 0s 763us/step - loss: 0.6088 - accuracy: 0.7500\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 0s 741us/step - loss: 0.5690 - accuracy: 0.7516\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 0s 740us/step - loss: 0.5911 - accuracy: 0.7676\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 0s 750us/step - loss: 0.5967 - accuracy: 0.7580\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6252 - accuracy: 0.7484\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5880 - accuracy: 0.7628\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.5960 - accuracy: 0.7564\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 0s 777us/step - loss: 0.6199 - accuracy: 0.7500\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 0s 735us/step - loss: 0.5905 - accuracy: 0.7596\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 0s 800us/step - loss: 0.6012 - accuracy: 0.7564\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 0s 801us/step - loss: 0.6153 - accuracy: 0.7484\n"
     ]
    }
   ],
   "source": [
    "#fitting and validation through cross validation\n",
    "\n",
    "for i in range(k):\n",
    "    print('fold num #',i+1)\n",
    "    \n",
    "    #validation data\n",
    "    val_data=X[i*num_val_samples:(i+1)*num_val_samples]\n",
    "    val_targets=y[i*num_val_samples:(i+1)*num_val_samples]\n",
    "    \n",
    "    #ready train data and target data\n",
    "    partial_train_data=np.concatenate([X[:i*num_val_samples], X[(i+1)*num_val_samples:]],axis=0)\n",
    "    partial_train_targets=np.concatenate([y[:i*num_val_samples], y[(i+1)*num_val_samples:]],axis=0)\n",
    "    \n",
    "    #Feature Scaling\n",
    "    partial_train_data=sc.fit_transform(partial_train_data)\n",
    "    val_data=sc.transform(val_data)\n",
    "    \n",
    "    #fitting\n",
    "    classifier.fit(partial_train_data, partial_train_targets, batch_size = 40, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29026f",
   "metadata": {},
   "source": [
    "### test - SJW ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "958ddc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "                 BYJ, HYN인 척 하는 SJW                  \n",
      "실제로 BYJ:\n",
      "[0.]\n",
      "실제로 HYN:\n",
      "[0.]\n",
      "실제로 SJW:\n",
      "[1.]\n",
      "--------------------------------------------------------\n",
      "               실제 AI 모델의 판단 결과                 \n",
      "BYJ으로 판단:\n",
      "[0.]\n",
      "HYN으로 판단:\n",
      "[0.]\n",
      "SJW으로 판단:\n",
      "[1.]\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./test_SJW.csv\")\n",
    "test_data = pd.get_dummies(test_data)\n",
    "test_data['Label_HYN'] = 0.0\n",
    "test_data['Label_BYJ'] = 0.0\n",
    "\n",
    "test_data = test_data.fillna(value=0.0)\n",
    "test_data = test_data.astype('float64')\n",
    "test_data = shuffle(test_data)\n",
    "\n",
    "user_count = 3\n",
    "X_len=len(test_data.columns)-user_count\n",
    "y_len=user_count\n",
    "\n",
    "X=test_data.iloc[:,0:X_len]\n",
    "y=test_data.iloc[:,-y_len:]\n",
    "\n",
    "test_pred=classifier.predict(X)\n",
    "test_pred=test_pred.tolist()\n",
    "num = len(test_pred[0])\n",
    "test_pred_df = pd.DataFrame(test_pred,columns=['Label_HYN', 'Label_BYJ', 'Label_SJW'])\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"                 BYJ, HYN인 척 하는 SJW                  \")\n",
    "print(\"실제로 BYJ:\", y[\"Label_BYJ\"].unique(), \n",
    "      \"실제로 HYN:\", y[\"Label_HYN\"].unique(), \n",
    "      \"실제로 SJW:\", y[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"               실제 AI 모델의 판단 결과                 \")\n",
    "print(\"BYJ으로 판단:\", test_pred_df[\"Label_BYJ\"].unique(), \n",
    "      \"HYN으로 판단:\", test_pred_df[\"Label_HYN\"].unique(), \n",
    "      \"SJW으로 판단:\", test_pred_df[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "test_pred_df.to_csv('./predict_SJW.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e46c3",
   "metadata": {},
   "source": [
    "### test - HYN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a79a0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "                 BYJ, SJW인 척 하는 HYN                  \n",
      "실제로 BYJ:\n",
      "[0.]\n",
      "실제로 HYN:\n",
      "[1.]\n",
      "실제로 SJW:\n",
      "[0.]\n",
      "--------------------------------------------------------\n",
      "               실제 AI 모델의 판단 결과                 \n",
      "BYJ으로 판단:\n",
      "[0.]\n",
      "HYN으로 판단:\n",
      "[1.]\n",
      "SJW으로 판단:\n",
      "[0.]\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./test_HYN.csv\")\n",
    "test_data = pd.get_dummies(test_data)\n",
    "test_data['Label_BYJ'] = 0.0\n",
    "test_data['Label_SJW'] = 0.0\n",
    "\n",
    "test_data = test_data.fillna(value=0.0)\n",
    "test_data = test_data.astype('float64')\n",
    "test_data = shuffle(test_data)\n",
    "\n",
    "user_count = 3\n",
    "X_len=len(test_data.columns)-user_count\n",
    "y_len=user_count\n",
    "\n",
    "X=test_data.iloc[:,0:X_len]\n",
    "y=test_data.iloc[:,-y_len:]\n",
    "\n",
    "test_pred=classifier.predict(X)\n",
    "test_pred=test_pred.tolist()\n",
    "num = len(test_pred[0])\n",
    "test_pred_df = pd.DataFrame(test_pred,columns=['Label_BYJ', 'Label_SJW', 'Label_HYN'])\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"                 BYJ, SJW인 척 하는 HYN                  \")\n",
    "print(\"실제로 BYJ:\", y[\"Label_BYJ\"].unique(), \n",
    "      \"실제로 HYN:\", y[\"Label_HYN\"].unique(), \n",
    "      \"실제로 SJW:\", y[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"               실제 AI 모델의 판단 결과                 \")\n",
    "print(\"BYJ으로 판단:\", test_pred_df[\"Label_BYJ\"].unique(), \n",
    "      \"HYN으로 판단:\", test_pred_df[\"Label_HYN\"].unique(), \n",
    "      \"SJW으로 판단:\", test_pred_df[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "test_pred_df.to_csv('./predict_HYN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff1acf",
   "metadata": {},
   "source": [
    "### test - BYJ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db7137cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "                 SJW, HYN인 척 하는 BYJ                  \n",
      "실제로 BYJ:\n",
      "[1.]\n",
      "실제로 HYN:\n",
      "[0.]\n",
      "실제로 SJW:\n",
      "[0.]\n",
      "--------------------------------------------------------\n",
      "               실제 AI 모델의 판단 결과                 \n",
      "BYJ으로 판단:\n",
      "[1.]\n",
      "HYN으로 판단:\n",
      "[0.]\n",
      "SJW으로 판단:\n",
      "[0.]\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./test_BYJ.csv\")\n",
    "test_data = pd.get_dummies(test_data)\n",
    "test_data['Label_SJW'] = 0.0\n",
    "test_data['Label_HYN'] = 0.0\n",
    "\n",
    "test_data = test_data.fillna(value=0.0)\n",
    "test_data = test_data.astype('float64')\n",
    "test_data = shuffle(test_data)\n",
    "\n",
    "user_count = 3\n",
    "X_len=len(test_data.columns)-user_count\n",
    "y_len=user_count\n",
    "\n",
    "X=test_data.iloc[:,0:X_len]\n",
    "y=test_data.iloc[:,-y_len:]\n",
    "\n",
    "test_pred=classifier.predict(X)\n",
    "test_pred=test_pred.tolist()\n",
    "num = len(test_pred[0])\n",
    "test_pred_df = pd.DataFrame(test_pred,columns=['Label_SJW', 'Label_HYN', 'Label_BYJ'])\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"                 SJW, HYN인 척 하는 BYJ                  \")\n",
    "print(\"실제로 BYJ:\", y[\"Label_BYJ\"].unique(), \n",
    "      \"실제로 HYN:\", y[\"Label_HYN\"].unique(), \n",
    "      \"실제로 SJW:\", y[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"               실제 AI 모델의 판단 결과                 \")\n",
    "print(\"BYJ으로 판단:\", test_pred_df[\"Label_BYJ\"].unique(), \n",
    "      \"HYN으로 판단:\", test_pred_df[\"Label_HYN\"].unique(), \n",
    "      \"SJW으로 판단:\", test_pred_df[\"Label_SJW\"].unique(), sep=\"\\n\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "test_pred_df.to_csv('./predict_BYJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814f719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
